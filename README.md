# Implementation of Transformer from [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper in [PyTorch](http://pytorch.org)

TODO:
* byte-pair encoding
* label smoothing
* beam search
* add tests
* batch bucketing
* visualize attention
